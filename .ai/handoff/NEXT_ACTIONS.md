# NEXT_ACTIONS â€” openclaw-gpu-bridge

> Updated: 2026-02-23

## âœ… Completed (v0.2 code scope)

- Multi-host support with failover and health checks
- Load balancing (`round-robin`, `least-busy`)
- Backward compatibility with v0.1 config
- Flexible model override + on-demand model cache in GPU service
- `/status` endpoint + progress logging
- README security/internet exposure documentation
- TypeScript unit tests for multi-host behavior (3/3 passing)

## ðŸ”œ Priority 1 â€” Live Validation (real hardware)

1. Start two GPU service instances/hosts and configure `hosts[]`
2. Verify round-robin distribution across hosts
3. Verify least-busy picks lower VRAM host under load
4. Kill one host during requests; verify automatic failover
5. Check `/status` reflects active jobs and progress
6. Auth verification on all hosts (`API_KEY`, 401/200 behavior)

## ðŸ”œ Priority 2 â€” Packaging & Release

1. Bump package release notes/changelog for v0.2.0
2. Publish npm package
3. Update production OpenClaw config to use `hosts[]`
4. Tag release in GitHub (`v0.2.0`)

## ðŸ”œ Priority 3 â€” Optional Hardening

- Add Python unit tests for model-cache and `/status`
- Add retry/backoff tuning per host (optional)
- Add host-level metrics endpoint/dashboard (optional)
